## 实现逻辑
采用多线程模型。逻辑如下：

主线程工作：
1. 读取两个csv文件，将所有内容放入内存，得到inner_table_rows/outer_table_rows
2. 将outer_table_rows数组按照线程数均分，每个线程相同大小的workload
3. 根据inner_table_rows数组构造hash表。这里使用C++中unordered_multimap
4. 启动多个线程，每个线程根据自己的workload，从hash表中进行查找，查找时同时计算是否满足非等之条件
5. 主线程等待各个线程执行结果，对count数目进行汇总

1到3，都是由主线程完成。第4步由多个线程完成，各个线程会根据自己的workload划分，从hash表中进行查找

## 如何执行
  make
  ./scripts/gen_data.sh
  ./scripts/perf.sh
  ./scripts/test_ndv.sh

## 测试
### 正确性
1. 包含一个简单的单测
2. 使用pg 导入csv文件进行验证，结果一致

### 性能测试
使用多线程，效果比较明显(./scripts/perf.sh)

线程数 | 时间
-- | --
1 | 2.02s
2 | 0.99s
4 | 0.47s
8 | 0.26s

### 遇到的问题
多线程测试时，发现线程数越多时，速度没有显著提升，反而略微下降

分析过程：起初认为是被限制了cpu核数，因为top 看到每次都只有200%的cpu消耗

后面发现是因为测试数据生成的逻辑有问题，导致发生了workload分配不均匀的情况。

数据特点：左表ndv为0.9，右表ndv为0.1。而且数据中a列是有序的，导致线程划分左表的数据时，有某两个线程的命中的概率会很大，其他线程命中的概率小

解决：修改数据生成的方式，让数据集是乱序的。但是有序的情况下是不是用merge join会更好

## ndv的影响
理论上，如果ndv比较小，可能会导致hash表某个桶很大，可能会退化成nested loop
join，失去了构造hash表的意义。造成某个值命中该桶后，需要进行的比较操作会很多。导致速度变慢

但是测试结果如下

左表ndv固定为0.9(./scripts/test_ndv.sh)

右表ndv | 时间
-- | --
0.1 | 10.93s
0.5 | 6.86s
0.7 | 6.81s
1 |  5.81s


## 优化以及扩展
1. hash表构建过程用单线程，可以采用多线程构建
